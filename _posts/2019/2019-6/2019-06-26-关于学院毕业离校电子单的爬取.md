---
layout: post
title: 关于学院毕业离校电子单的爬取 
date: 2019-06-26 08:58:15 +0800 
categories: Python 
tags: ["Python", "爬虫"]
comments: false
description: 学校离校，有电子档案什么的，比如教务处，计财处，图书馆等等的审核，审核通过之后，最终完成之后才会发毕业证。而有的同学是不在学校，而在校外访问需要vpn，我昨天晚上就想，我是不是能爬取这些信息下来，然后用一个网页显示出来呢？于是我有了下面的思路和结果。
---
## 解析网站登录情况

网址是：`http://202.115.158.19/xhu-egraduation-main/j_spring_security_check?logurl=/index!mgr.action&Verify=false&logintype=wz`

登录是使用学号和姓名，登录模块有验证码，在尝试输错的情况下，是可以登录进去的，通过网站的ico图标，可以判断是tomcat容器，java做的，应该是jsp，通过单独的页面，

登录成功后，获取是否成功的页面，是有一个get请求，当登录成功后，可以直接获取那个请求，会得到一个页面，而实际上，是ajax去请求那个页面（组件页面jsp），python直接可以获取。

## 选择爬取（使用说明）

{% gist 710b731b800e710f343c3f611a8fe60d a使用方式.txt %}

## 爬取

{% gist 710b731b800e710f343c3f611a8fe60d src_read.py %}

## 修改首页

{% gist 710b731b800e710f343c3f611a8fe60d src_rindex.py %}

## 效果图

爬取下来后，根据rindex.py生成一个关于内容的首页，一个链接指向具体的位置。

![one][bg1]

在爬取的过程中一部分输出的内容

![two][bg2]

在爬取完成后显示结果
![three][bg3]

## 代码略解

python使用了requests包，因为使用了会话，登录后连接的信息具有关联性，所以使用requests.session。请求，返回信息，再请求得到对应的电子单的页面。

第二次分析的时候添加了检测是否通过的功能，把内容爬取下来，使用beautifulSoup进行解析是否具有没有通过的class，具有几个那么就是有几个没有通过。

通过分析，请求具有失败性，所以有try exception来解决错误，所以重复性的爬取，检测到具有那个文件就不再爬取，第一次是通过自己查看输出的错误文档，每次爬取都有一个文档，第二次一直输入一个文档，但是有个最终的标志，如果执行两次，其中没有错误的显示，那么就证明所有的都爬取下来了。

- 2019年6月20日 早8：12 改（添加代码略解）

[bg1]: https://res.cloudinary.com/xiongxiao/image/upload/v1561822376/github/images/Snipaste_2019-06-29_23-28-12.png "获得信息的首页"
[bg2]: https://res.cloudinary.com/xiongxiao/image/upload/v1561822376/github/images/Snipaste_2019-06-29_23-31-29.png "中途生成html"
[bg3]: https://res.cloudinary.com/xiongxiao/image/upload/v1561822375/github/images/Snipaste_2019-06-29_23-30-15.png "生成结果"